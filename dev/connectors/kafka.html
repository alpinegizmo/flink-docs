<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.2-SNAPSHOT Documentation: Apache Kafka Connector</title>
    <link rel="shortcut icon" href="https://alpinegizmo.github.io/flink-docs//page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://alpinegizmo.github.io/flink-docs//page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/flink.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/syntax.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/codetabs.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <!-- Main content. -->
    <div class="container">
      

      
      <div class="row">
        <div class="col-lg-3">
          







  
    
    
    
      
    
  

  
    
    
    
      
    
  

  
    
    
    
      













<div class="sidenav-logo">
  <p><a href="https://alpinegizmo.github.io/flink-docs/"><img class="bottom" alt="Apache Flink" src="https://alpinegizmo.github.io/flink-docs//page/img/navbar-brand-logo.jpg"></a> v1.2-SNAPSHOT</p>
</div>
<ul id="sidenav">

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li>
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title appetizer" aria-hidden="true"></i> Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//concepts/programming-model.html">Programming Model</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/setup_quickstart.html"><i class="fa fa-power-off title appetizer" aria-hidden="true"></i> Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse"><i class="fa fa-file-code-o title appetizer" aria-hidden="true"></i> Examples <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-7"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/run_example_quickstart.html">Monitoring Wikipedia Edits</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-10" data-toggle="collapse" class="active"><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</a><div class="collapse in" id="collapse-10"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-11" data-toggle="collapse">Installation & Setup <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-11"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/java_api_quickstart.html">Java Projects</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/scala_api_quickstart.html">Scala Projects</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/scala_shell.html">Scala REPL</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/linking.html">Linking with Optional Modules</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-20" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-20"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/datastream_api.html">Streaming (DataStream API)</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/windows.html">Windows</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-26" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-26"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_timestamp_extractors.html">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-30" data-toggle="collapse" class="active">Connectors</a><div class="collapse in" id="collapse-30"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/kafka.html" class="active">Kafka</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/kinesis.html">Kinesis</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/elasticsearch2.html">Elasticsearch 2.x</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/redis.html">Redis</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/state.html">State & Checkpointing</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/fault_tolerance.html">Failure & Recovery Model</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/types_serialization.html">Data Types & Serialization</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/execution.html">Managing Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-46" data-toggle="collapse">Batch (DataSet API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-46"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/examples.html">Examples</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-57" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-57"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/table_api.html">Table and SQL</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/storm_compatibility.html">Storm Compatibility</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-61" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-61"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-68" data-toggle="collapse">Machine Learning <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-68"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/quickstart.html">Quickstart</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/contribution_guide.html">How to Contribute</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/cross_validation.html">Cross Validation</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/distance_metrics.html">Distance Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/knn.html">k-Nearest Neighbors Join</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/min_max_scaler.html">MinMax Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/multiple_linear_regression.html">Multiple Linear Regression</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/optimization.html">Optimization</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/polynomial_features.html">Polynomial Features</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/standard_scaler.html">Standard Scaler</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/svm.html">SVM using CoCoA</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/config.html"><i class="fa fa-sliders title maindish" aria-hidden="true"></i> Configuration</a></li>
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-86" data-toggle="collapse"><i class="fa fa-cogs title maindish" aria-hidden="true"></i> Deployment & Operations <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/cli.html">CLI</a></li>
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-88" data-toggle="collapse">Deployment <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-88"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/yarn_setup.html">YARN</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/aws.html">AWS</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/jobmanager_high_availability.html">High Availability (HA)</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/savepoints.html">Savepoints</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/state_backends.html">State Backends</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    

    
    
      
      
        
        
<li><a href="#collapse-99" data-toggle="collapse"><i class="fa fa-bug title maindish" aria-hidden="true"></i> Debugging & Monitoring <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/logging.html">Logging</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/back_pressure.html">Back Pressure Monitoring</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/best_practices.html">Best Practices</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    <hr class="section-break"></hr>

    
    
      
      
        
        
<li><a href="#collapse-106" data-toggle="collapse"><i class="fa fa-book title dessert" aria-hidden="true"></i> Internals <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-106"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/components.html">Component Stack</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/dependencies.html">Projects and Dependencies</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    

    
    
    

    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/add_operator.html">Adding a new DataSet Operator</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
  <li class="divider"></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="https://alpinegizmo.github.io/flink-docs//search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search Docs">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content">
          

          





  
  
    
    
      
    
  

  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-code title maindish" aria-hidden="true"></i> Application Development</li>
  

  
  
    <li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/">Connectors</a></li>
  

  
  
    <li class="active">Kafka</li>
  

</ol>

<h1>Apache Kafka Connector</h1>



<p>This connector provides access to event streams served by <a href="https://kafka.apache.org/">Apache Kafka</a>.</p>

<p>Flink provides special Kafka Connectors for reading and writing data from/to Kafka topics.
The Flink Kafka Consumer integrates with Flink’s checkpointing mechanism to provide
exactly-once processing semantics. To achieve that, Flink does not purely rely on Kafka’s consumer group
offset tracking, but tracks and checkpoints these offsets internally as well.</p>

<p>Please pick a package (maven artifact id) and class name for your use-case and environment.
For most users, the <code>FlinkKafkaConsumer08</code> (part of <code>flink-connector-kafka</code>) is appropriate.</p>

<table class="table table-bordered">
  <thead>
    <tr>
      <th class="text-left">Maven Dependency</th>
      <th class="text-left">Supported since</th>
      <th class="text-left">Consumer and <br />
      Producer Class name</th>
      <th class="text-left">Kafka version</th>
      <th class="text-left">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>flink-connector-kafka-0.8_2.10</td>
        <td>1.0.0</td>
        <td>FlinkKafkaConsumer08<br />
        FlinkKafkaProducer08</td>
        <td>0.8.x</td>
        <td>Uses the <a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example">SimpleConsumer</a> API of Kafka internally. Offsets are committed to ZK by Flink.</td>
    </tr>
    <tr>
        <td>flink-connector-kafka-0.9_2.10</td>
        <td>1.0.0</td>
        <td>FlinkKafkaConsumer09<br />
        FlinkKafkaProducer09</td>
        <td>0.9.x</td>
        <td>Uses the new <a href="http://kafka.apache.org/documentation.html#newconsumerapi">Consumer API</a> Kafka.</td>
    </tr>
    <tr>
        <td>flink-connector-kafka-0.10_2.10</td>
        <td>1.2.0</td>
        <td>FlinkKafkaConsumer010<br />
        FlinkKafkaProducer010</td>
        <td>0.10.x</td>
        <td>This connector supports <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message">Kafka messages with timestamps</a> both for producing and consuming.</td>
    </tr>
  </tbody>
</table>

<p>Then, import the connector in your maven project:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-connector-kafka-0.8_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.2-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p>Note that the streaming connectors are currently not part of the binary distribution. See how to link with them for cluster execution <a href="https://alpinegizmo.github.io/flink-docs//dev/linking">here</a>.</p>

<h3 id="installing-apache-kafka">Installing Apache Kafka</h3>

<ul>
  <li>Follow the instructions from <a href="https://kafka.apache.org/documentation.html#quickstart">Kafka’s quickstart</a> to download the code and launch a server (launching a Zookeeper and a Kafka server is required every time before starting the application).</li>
  <li>If the Kafka and Zookeeper servers are running on a remote machine, then the <code>advertised.host.name</code> setting in the <code>config/server.properties</code> file must be set to the machine’s IP address.</li>
</ul>

<h3 id="kafka-consumer">Kafka Consumer</h3>

<p>Flink’s Kafka consumer is called <code>FlinkKafkaConsumer08</code> (or <code>09</code> for Kafka 0.9.0.x versions). It provides access to one or more Kafka topics.</p>

<p>The constructor accepts the following arguments:</p>

<ol>
  <li>The topic name / list of topic names</li>
  <li>A DeserializationSchema / KeyedDeserializationSchema for deserializing the data from Kafka</li>
  <li>Properties for the Kafka consumer.
  The following properties are required:
    <ul>
      <li>“bootstrap.servers” (comma separated list of Kafka brokers)</li>
      <li>“zookeeper.connect” (comma separated list of Zookeeper servers) (<strong>only required for Kafka 0.8</strong>)</li>
      <li>“group.id” the id of the consumer group</li>
    </ul>
  </li>
</ol>

<p>Example:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span>
	<span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKafkaConsumer08</span><span class="o">&lt;&gt;(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">))</span>
	<span class="o">.</span><span class="na">print</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaConsumer08</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">))</span>
    <span class="o">.</span><span class="n">print</span></code></pre></figure>

  </div>
</div>

<p>The current FlinkKafkaConsumer implementation will establish a connection from the client (when calling the constructor)
for querying the list of topics and partitions.</p>

<p>For this to work, the consumer needs to be able to access the consumers from the machine submitting the job to the Flink cluster.
If you experience any issues with the Kafka consumer on the client side, the client log might contain information about failed requests, etc.</p>

<h4 id="the-">The <code>DeserializationSchema</code></h4>

<p>The Flink Kafka Consumer needs to know how to turn the binary data in Kafka into Java/Scala objects. The
<code>DeserializationSchema</code> allows users to specify such a schema. The <code>T deserialize(byte[] message)</code>
method gets called for each Kafka message, passing the value from Kafka.</p>

<p>It is usually helpful to start from the <code>AbstractDeserializationSchema</code>, which takes care of describing the
produced Java/Scala type to Flink’s type system. Users that implement a vanilla <code>DeserializationSchema</code> need
to implement the <code>getProducedType(...)</code> method themselves.</p>

<p>For accessing both the key and value of the Kafka message, the <code>KeyedDeserializationSchema</code> has
the following deserialize method ` T deserialize(byte[] messageKey, byte[] message, String topic, int partition, long offset)`.</p>

<p>For convenience, Flink provides the following schemas:</p>

<ol>
  <li>
    <p><code>TypeInformationSerializationSchema</code> (and <code>TypeInformationKeyValueSerializationSchema</code>) which creates
 a schema based on a Flink’s <code>TypeInformation</code>. This is useful if the data is both written and read by Flink.
 This schema is a performant Flink-specific alternative to other generic serialization approaches.</p>
  </li>
  <li>
    <p><code>JsonDeserializationSchema</code> (and <code>JSONKeyValueDeserializationSchema</code>) which turns the serialized JSON
 into an ObjectNode object, from which fields can be accessed using objectNode.get(“field”).as(Int/String/…)().
 The KeyValue objectNode contains a “key” and “value” field which contain all fields, as well as
 an optional “metadata” field that exposes the offset/partition/topic for this message.</p>
  </li>
</ol>

<h4 id="kafka-consumers-and-fault-tolerance">Kafka Consumers and Fault Tolerance</h4>

<p>With Flink’s checkpointing enabled, the Flink Kafka Consumer will consume records from a topic and periodically checkpoint all
its Kafka offsets, together with the state of other operations, in a consistent manner. In case of a job failure, Flink will restore
the streaming program to the state of the latest checkpoint and re-consume the records from Kafka, starting from the offsets that where
stored in the checkpoint.</p>

<p>The interval of drawing checkpoints therefore defines how much the program may have to go back at most, in case of a failure.</p>

<p>To use fault tolerant Kafka Consumers, checkpointing of the topology needs to be enabled at the execution environment:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">);</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">)</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
</div>

<p>Also note that Flink can only restart the topology if enough processing slots are available to restart the topology.
So if the topology fails due to loss of a TaskManager, there must still be enough slots available afterwards.
Flink on YARN supports automatic restart of lost YARN containers.</p>

<p>If checkpointing is not enabled, the Kafka consumer will periodically commit the offsets to Zookeeper.</p>

<h4 id="kafka-consumers-and-timestamp-extractionwatermark-emission">Kafka Consumers and Timestamp Extraction/Watermark Emission</h4>

<p>In many scenarios, the timestamp of a record is embedded (explicitly or implicitly) in the record itself.
In addition, the user may want to emit watermarks either periodically, or in an irregular fashion, e.g. based on
special records in the Kafka stream that contain the current event-time watermark. For these cases, the Flink Kafka
Consumer allows the specification of an <code>AssignerWithPeriodicWatermarks</code> or an <code>AssignerWithPunctuatedWatermarks</code>.</p>

<p>You can specify your custom timestamp extractor/watermark emitter as described
<a href="https://alpinegizmo.github.io/flink-docs//apis/streaming/event_timestamps_watermarks.html">here</a>, or use one from the
<a href="https://alpinegizmo.github.io/flink-docs//apis/streaming/event_timestamp_extractors.html">predefined ones</a>. After doing so, you
can pass it to your consumer in the following way:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">properties</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="na">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>

<span class="n">FlinkKafkaConsumer08</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">myConsumer</span> <span class="o">=</span>
    <span class="k">new</span> <span class="n">FlinkKafkaConsumer08</span><span class="o">&lt;&gt;(</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">);</span>
<span class="n">myConsumer</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="k">new</span> <span class="nf">CustomWatermarkEmitter</span><span class="o">());</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span>
	<span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="n">myConsumer</span><span class="o">)</span>
	<span class="o">.</span><span class="na">print</span><span class="o">();</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">properties</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;bootstrap.servers&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:9092&quot;</span><span class="o">);</span>
<span class="c1">// only required for Kafka 0.8</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;zookeeper.connect&quot;</span><span class="o">,</span> <span class="s">&quot;localhost:2181&quot;</span><span class="o">);</span>
<span class="n">properties</span><span class="o">.</span><span class="n">setProperty</span><span class="o">(</span><span class="s">&quot;group.id&quot;</span><span class="o">,</span> <span class="s">&quot;test&quot;</span><span class="o">);</span>

<span class="k">val</span> <span class="n">myConsumer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FlinkKafkaConsumer08</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">);</span>
<span class="n">myConsumer</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomWatermarkEmitter</span><span class="o">());</span>
<span class="n">stream</span> <span class="k">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="n">myConsumer</span><span class="o">)</span>
    <span class="o">.</span><span class="n">print</span></code></pre></figure>

  </div>
</div>

<p>Internally, an instance of the assigner is executed per Kafka partition.
When such an assigner is specified, for each record read from Kafka, the
<code>extractTimestamp(T element, long previousElementTimestamp)</code> is called to assign a timestamp to the record and
the <code>Watermark getCurrentWatermark()</code> (for periodic) or the
<code>Watermark checkAndGetNextWatermark(T lastElement, long extractedTimestamp)</code> (for punctuated) is called to determine
if a new watermark should be emitted and with which timestamp.</p>

<h3 id="kafka-producer">Kafka Producer</h3>

<p>The <code>FlinkKafkaProducer08</code> writes data to a Kafka topic. The producer can specify a custom partitioner that assigns
records to partitions.</p>

<p>Example:</p>

<div class="codetabs">
  <div data-lang="java, Kafka 0.8+">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">stream</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKafkaProducer08</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;(</span><span class="s">&quot;localhost:9092&quot;</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">()));</span></code></pre></figure>

  </div>
  <div data-lang="java, Kafka 0.10+">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">FlinkKafkaProducer010</span><span class="o">.</span><span class="na">writeToKafkaWithTimestamps</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala, Kafka 0.8+">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="n">stream</span><span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKafkaProducer08</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;localhost:9092&quot;</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">()))</span></code></pre></figure>

  </div>
  <div data-lang="scala, Kafka 0.10+">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="nc">FlinkKafkaProducer010</span><span class="o">.</span><span class="n">writeToKafkaWithTimestamps</span><span class="o">(</span><span class="n">stream</span><span class="o">,</span> <span class="s">&quot;my-topic&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">(),</span> <span class="n">properties</span><span class="o">);</span></code></pre></figure>

  </div>
</div>

<p>You can also define a custom Kafka producer configuration for the KafkaSink with the constructor. Please refer to
the <a href="https://kafka.apache.org/documentation.html">Apache Kafka documentation</a> for details on how to configure
Kafka Producers.</p>

<p>Similar to the consumer, the producer also allows using an advanced serialization schema which allows
serializing the key and value separately. It also allows to override the target topic id, so that
one producer instance can send data to multiple topics.</p>

<p>The interface of the serialization schema is called <code>KeyedSerializationSchema</code>.</p>

<p><strong>Note</strong>: By default, the number of retries is set to “0”. This means that the producer fails immediately on errors,
including leader changes. The value is set to “0” by default to avoid duplicate messages in the target topic.
For most production environments with frequent broker changes, we recommend setting the number of retries to a
higher value.</p>

<p>There is currently no transactional producer for Kafka, so Flink can not guarantee exactly-once delivery
into a Kafka topic.</p>

<h3 id="using-kafka-timestamps-and-flink-event-time-in-kafka-010">Using Kafka timestamps and Flink event time in Kafka 0.10</h3>

<p>Since Apache Kafka 0.10., Kafka’s messages can carry <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-32+-+Add+timestamps+to+Kafka+message">timestamps</a>, indicating
the time the event has occurred (see <a href="../event_time.html">“event time” in Apache Flink</a>) or the time when the message
has been written to the Kafka broker.</p>

<p>The <code>FlinkKafkaConsumer010</code> will emit records with the timestamp attached, if the time characteristic in Flink is 
set to <code>TimeCharacteristic.EventTime</code> (<code>StreamExecutionEnvironment.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)</code>).</p>

<p>The Kafka consumer does not emit watermarks. To emit watermarks, the same mechanisms as described above in 
“Kafka Consumers and Timestamp Extraction/Watermark Emission”  using the <code>assignTimestampsAndWatermarks</code> method are applicable.</p>

<p>There is no need to define a timestamp extractor when using the timestamps from Kafka. The <code>previousElementTimestamp</code> argument of 
the <code>extractTimestamp()</code> method contains the timestamp carried by the Kafka message.</p>

<p>A timestamp extractor for a Kafka consumer would look like this:</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kt">long</span> <span class="nf">extractTimestamp</span><span class="o">(</span><span class="n">Long</span> <span class="n">element</span><span class="o">,</span> <span class="kt">long</span> <span class="n">previousElementTimestamp</span><span class="o">)</span> <span class="o">{</span>
    <span class="k">return</span> <span class="n">previousElementTimestamp</span><span class="o">;</span>
<span class="o">}</span></code></pre></figure>

<p>The <code>FlinkKafkaProducer010</code> only emits the record timestamp, if <code>setWriteTimestampToKafka(true)</code> is set.</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">FlinkKafkaProducer010</span><span class="o">.</span><span class="na">FlinkKafkaProducer010Configuration</span> <span class="n">config</span> <span class="o">=</span> <span class="n">FlinkKafkaProducer010</span><span class="o">.</span><span class="na">writeToKafkaWithTimestamps</span><span class="o">(</span><span class="n">streamWithTimestamps</span><span class="o">,</span> <span class="n">topic</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">standardProps</span><span class="o">);</span>
<span class="n">config</span><span class="o">.</span><span class="na">setWriteTimestampToKafka</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span></code></pre></figure>



        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="https://alpinegizmo.github.io/flink-docs//page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
