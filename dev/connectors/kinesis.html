<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink 1.2-SNAPSHOT Documentation: Amazon AWS Kinesis Streams Connector</title>
    <link rel="shortcut icon" href="https://alpinegizmo.github.io/flink-docs//page/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://alpinegizmo.github.io/flink-docs//page/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/flink.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/syntax.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/css/codetabs.css">
    <link rel="stylesheet" href="https://alpinegizmo.github.io/flink-docs//page/font-awesome/css/font-awesome.min.css">
    
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <!-- Main content. -->
    <div class="container">
      

      
      <div class="row">
        <div class="col-lg-3">
          







  
    
    
    
      
    
  

  
    
    
    
      
    
  

  
    
    
    
      













<div class="sidenav-logo">
  <p><a href="https://alpinegizmo.github.io/flink-docs/"><img class="bottom" alt="Apache Flink" src="https://alpinegizmo.github.io/flink-docs//page/img/navbar-brand-logo.jpg"></a> v1.2-SNAPSHOT</p>
</div>
<ul id="sidenav">

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//"><i class="fa fa-home title" aria-hidden="true"></i> Home</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-2" data-toggle="collapse"><i class="fa fa-map-o title" aria-hidden="true"></i> Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-2"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//concepts/programming-model.html">Programming Model</a></li>
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//concepts/runtime.html">Distributed Runtime</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/setup_quickstart.html"><i class="fa fa-power-off title" aria-hidden="true"></i> Quickstart</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-7" data-toggle="collapse" class="active"><i class="fa fa-code title" aria-hidden="true"></i> Application Development</a><div class="collapse in" id="collapse-7"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-8" data-toggle="collapse">Installation & Setup <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-8"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/ide_setup.html">IDE Setup</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/java_api_quickstart.html">Java Projects</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/scala_api_quickstart.html">Scala Projects</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/scala_shell.html">Scala REPL</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/flink_on_windows.html">Running Flink on Windows</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/linking.html">Linking with Optional Modules</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/building.html">Building Flink from Source</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-17" data-toggle="collapse">Basic API Concepts <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-17"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/api_concepts.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/scala_api_extensions.html">Scala API Extensions</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/java8.html">Java 8</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/datastream_api.html">Streaming (DataStream API)</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/windows.html">Windows</a></li>
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-23" data-toggle="collapse">Event Time <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-23"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_time.html">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_timestamps_watermarks.html">Generating Timestamps / Watermarks</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/event_timestamp_extractors.html">Pre-defined Timestamp Extractors / Watermark Emitters</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-27" data-toggle="collapse" class="active">Connectors</a><div class="collapse in" id="collapse-27"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/kafka.html">Kafka</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/cassandra.html">Cassandra</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/kinesis.html" class="active">Kinesis</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/elasticsearch.html">Elasticsearch</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/elasticsearch2.html">Elasticsearch 2.x</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/filesystem_sink.html">Rolling File Sink</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/rabbitmq.html">RabbitMQ</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/nifi.html">NiFi</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/redis.html">Redis</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/twitter.html">Twitter</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/state.html">State & Checkpointing</a></li>
      
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/fault_tolerance.html">Failure & Recovery Model</a></li>
      
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/types_serialization.html">Data Types & Serialization</a></li>
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/execution.html">Managing Execution</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-43" data-toggle="collapse">Batch (DataSet API) <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-43"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/dataset_transformations.html">Transformations</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/fault_tolerance.html">Fault Tolerance</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/zip_elements_guide.html">Zipping Elements</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/connectors.html">Connectors</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/python.html">Python API</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/examples.html">Examples</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/batch/hadoop_compatibility.html">Hadoop Compatibility</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/local_execution.html">Local Execution</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/cluster_execution.html">Cluster Execution</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-54" data-toggle="collapse">Libraries <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-54"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/table_api.html">Table and SQL</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/cep.html">Event Processing (CEP)</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/storm_compatibility.html">Storm Compatibility</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-58" data-toggle="collapse">Graphs: Gelly <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-58"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_api.html">Graph API</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/iterative_graph_processing.html">Iterative Graph Processing</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/library_methods.html">Library Methods</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_algorithms.html">Graph Algorithms</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/gelly/graph_generators.html">Graph Generators</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-65" data-toggle="collapse">Machine Learning <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-65"><ul>
  <li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/">Overview</a></li>
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/quickstart.html">Quickstart</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/als.html">ALS</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/contribution_guide.html">How to Contribute</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/cross_validation.html">Cross Validation</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/distance_metrics.html">Distance Metrics</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/knn.html">k-Nearest Neighbors Join</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/min_max_scaler.html">MinMax Scaler</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/multiple_linear_regression.html">Multiple Linear Regression</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/optimization.html">Optimization</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/pipelines.html">Pipelines</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/polynomial_features.html">Polynomial Features</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/standard_scaler.html">Standard Scaler</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/libs/ml/svm.html">SVM using CoCoA</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-82" data-toggle="collapse"><i class="fa fa-file-code-o title" aria-hidden="true"></i> Examples <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-82"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//quickstart/run_example_quickstart.html">Monitoring Wikipedia Edits</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/config.html"><i class="fa fa-sliders title" aria-hidden="true"></i> Configuration</a></li>
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-86" data-toggle="collapse"><i class="fa fa-cogs title" aria-hidden="true"></i> Deployment & Operations <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-86"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/cli.html">CLI</a></li>
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-88" data-toggle="collapse">Deployment <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-88"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/cluster_setup.html">Standalone Cluster</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/yarn_setup.html">YARN</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/aws.html">AWS</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/gce_setup.html">Google Compute Engine</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/jobmanager_high_availability.html">High Availability (HA)</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/savepoints.html">Savepoints</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//setup/security-ssl.html">SSL Setup</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//dev/state_backends.html">State Backends</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-99" data-toggle="collapse"><i class="fa fa-bug title" aria-hidden="true"></i> Debugging & Monitoring <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-99"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/metrics.html">Metrics</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/logging.html">Logging</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/rest_api.html">Monitoring REST API</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/back_pressure.html">Back Pressure Monitoring</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//monitoring/best_practices.html">Best Practices</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    

    

    
    
    

    
    
      
      
        
        
<li><a href="#collapse-106" data-toggle="collapse"><i class="fa fa-book title" aria-hidden="true"></i> Internals <i class="fa fa-caret-down pull-right" aria-hidden="true" style="padding-top: 4px"></i></a><div class="collapse" id="collapse-106"><ul>
  
        
        
        

        
        
      
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/components.html">Component Stack</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/dependencies.html">Projects and Dependencies</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/stream_checkpointing.html">Fault Tolerance for Data Streaming</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/job_scheduling.html">Jobs and Scheduling</a></li>
    
  

  
    

    

    
    
    

    
    
<li><a href="https://alpinegizmo.github.io/flink-docs//internals/add_operator.html">Adding a new DataSet Operator</a></li>
    
  

  
    
      
      
</li></ul></div>
      
      
    
  

  
    
      
  <li class="divider"></li>
  <li><a href="http://flink.apache.org"><i class="fa fa-external-link title" aria-hidden="true"></i> Project Page</a></li>
</ul>

<div class="sidenav-search-box">
  <form class="navbar-form" role="search" action="https://alpinegizmo.github.io/flink-docs//search-results.html">
    <div class="form-group">
      <input type="text" class="form-control" size="16px" name="q" placeholder="Search Docs">
    </div>
    <button type="submit" class="btn btn-default">Go</button>
  </form>
</div>

<div class="sidenav-versions">
  <div class="dropdown">
    <button class="btn btn-default dropdown-toggle" type="button" data-toggle="dropdown">Pick Docs Version
    <span class="caret"></span></button>
    <ul class="dropdown-menu">
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.1">v1.1</a></li>
      
      <li><a href="http://ci.apache.org/projects/flink/flink-docs-release-1.0">v1.0</a></li>
      
    </ul>
  </div>
</div>

        </div>
        <div class="col-lg-9 content">
          

          





  
  
    
    
      
    
  

  
  
    
    
      
    
  

  
  
    
    
      



<ol class="breadcrumb">

  
  
    <li><i class="fa fa-code title" aria-hidden="true"></i> Application Development</li>
  

  
  
    <li><a href="https://alpinegizmo.github.io/flink-docs//dev/connectors/">Connectors</a></li>
  

  
  
    <li class="active">Kinesis</li>
  

</ol>

<h1>Amazon AWS Kinesis Streams Connector</h1>



<p>The Kinesis connector provides access to <a href="http://aws.amazon.com/kinesis/streams/">Amazon AWS Kinesis Streams</a>.</p>

<p>To use the connector, add the following Maven dependency to your project:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-connector-kinesis_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.2-SNAPSHOT<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></figure>

<p><strong>The <code>flink-connector-kinesis_2.10</code> has a dependency on code licensed under the <a href="https://aws.amazon.com/asl/">Amazon Software License</a> (ASL).
Linking to the flink-connector-kinesis will include ASL licensed code into your application.</strong></p>

<p>The <code>flink-connector-kinesis_2.10</code> artifact is not deployed to Maven central as part of
Flink releases because of the licensing issue. Therefore, you need to build the connector yourself from the source.</p>

<p>Download the Flink source or check it out from the git repository. Then, use the following Maven command to build the module:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">mvn clean install -Pinclude-kinesis -DskipTests
<span class="c"># In Maven 3.3 the shading of flink-dist doesn&#39;t work properly in one run, so we need to run mvn for flink-dist again.</span>
<span class="nb">cd </span>flink-dist
mvn clean install -Pinclude-kinesis -DskipTests</code></pre></figure>

<p>The streaming connectors are not part of the binary distribution. See how to link with them for cluster
execution <a href="https://alpinegizmo.github.io/flink-docs//dev/linking">here</a>.</p>

<h3 id="using-the-amazon-kinesis-streams-service">Using the Amazon Kinesis Streams Service</h3>
<p>Follow the instructions from the <a href="https://docs.aws.amazon.com/streams/latest/dev/learning-kinesis-module-one-create-stream.html">Amazon Kinesis Streams Developer Guide</a>
to setup Kinesis streams. Make sure to create the appropriate IAM policy and user to read / write to the Kinesis streams.</p>

<h3 id="kinesis-consumer">Kinesis Consumer</h3>

<p>The <code>FlinkKinesisConsumer</code> is an exactly-once parallel streaming data source that subscribes to multiple AWS Kinesis
streams within the same AWS service region, and can handle resharding of streams. Each subtask of the consumer is
responsible for fetching data records from multiple Kinesis shards. The number of shards fetched by each subtask will
change as shards are closed and created by Kinesis.</p>

<p>Before consuming data from Kinesis streams, make sure that all streams are created with the status “ACTIVE” in the AWS dashboard.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">consumerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ConsumerConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ConsumerConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ConsumerConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ConsumerConfigConstants</span><span class="o">.</span><span class="na">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">&quot;LATEST&quot;</span><span class="o">);</span>

<span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getEnvironment</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">consumerConfig</span><span class="o">));</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">consumerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="nc">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="nc">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="nc">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>
<span class="n">consumerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ConsumerConfigConstants</span><span class="o">.</span><span class="nc">STREAM_INITIAL_POSITION</span><span class="o">,</span> <span class="s">&quot;LATEST&quot;</span><span class="o">);</span>

<span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getEnvironment</span>

<span class="k">val</span> <span class="n">kinesis</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">consumerConfig</span><span class="o">))</span></code></pre></figure>

  </div>
</div>

<p>The above is a simple example of using the consumer. Configuration for the consumer is supplied with a <code>java.util.Properties</code>
instance, the configuration keys for which can be found in <code>ConsumerConfigConstants</code>. The example
demonstrates consuming a single Kinesis stream in the AWS region “us-east-1”. The AWS credentials are supplied using the basic method in which
the AWS access key ID and secret access key are directly supplied in the configuration (other options are setting
<code>ConsumerConfigConstants.AWS_CREDENTIALS_PROVIDER</code> to <code>ENV_VAR</code>, <code>SYS_PROP</code>, <code>PROFILE</code>, and <code>AUTO</code>). Also, data is being consumed
from the newest position in the Kinesis stream (the other option will be setting <code>ConsumerConfigConstants.STREAM_INITIAL_POSITION</code>
to <code>TRIM_HORIZON</code>, which lets the consumer start reading the Kinesis stream from the earliest record possible).</p>

<p>Other optional configuration keys for the consumer can be found in <code>ConsumerConfigConstants</code>.</p>

<p><strong>NOTE:</strong> Currently, resharding can not be handled transparently (i.e., without failing and restarting jobs) if there are idle consumer
subtasks, which occur when the total number of shards is lower than the configured consumer parallelism. The job must be
configured to enable checkpointing, so that the new shards due to resharding can be correctly picked up and consumed by the
Kinesis consumer after the job is restored. This is a temporary limitation that will be resolved in future versions.
Please see <a href="https://issues.apache.org/jira/browse/FLINK-4341">FLINK-4341</a> for more detail.</p>

<h4 id="fault-tolerance-for-exactly-once-user-defined-state-update-semantics">Fault Tolerance for Exactly-Once User-Defined State Update Semantics</h4>

<p>With Flink’s checkpointing enabled, the Flink Kinesis Consumer will consume records from shards in Kinesis streams and
periodically checkpoint each shard’s progress. In case of a job failure, Flink will restore the streaming program to the
state of the latest complete checkpoint and re-consume the records from Kinesis shards, starting from the progress that
was stored in the checkpoint.</p>

<p>The interval of drawing checkpoints therefore defines how much the program may have to go back at most, in case of a failure.</p>

<p>To use fault tolerant Kinesis Consumers, checkpointing of the topology needs to be enabled at the execution environment:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">);</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">enableCheckpointing</span><span class="o">(</span><span class="mi">5000</span><span class="o">)</span> <span class="c1">// checkpoint every 5000 msecs</span></code></pre></figure>

  </div>
</div>

<p>Also note that Flink can only restart the topology if enough processing slots are available to restart the topology.
Therefore, if the topology fails due to loss of a TaskManager, there must still be enough slots available afterwards.
Flink on YARN supports automatic restart of lost YARN containers.</p>

<h4 id="event-time-for-consumed-records">Event Time for Consumed Records</h4>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setStreamTimeCharacteristic</span><span class="o">(</span><span class="n">TimeCharacteristic</span><span class="o">.</span><span class="na">EventTime</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">setStreamTimeCharacteristic</span><span class="o">(</span><span class="nc">TimeCharacteristic</span><span class="o">.</span><span class="nc">EventTime</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<p>If streaming topologies choose to use the <a href="https://alpinegizmo.github.io/flink-docs//apis/streaming/event_time.html">event time notion</a> for record
timestamps, an <em>approximate arrival timestamp</em> will be used by default. This timestamp is attached to records by Kinesis once they
were successfully received and stored by streams. Note that this timestamp is typically referred to as a Kinesis server-side
timestamp, and there are no guarantees about the accuracy or order correctness (i.e., the timestamps may not always be
ascending).</p>

<p>Users can choose to override this default with a custom timestamp, as described <a href="https://alpinegizmo.github.io/flink-docs//apis/streaming/event_timestamps_watermarks.html">here</a>,
or use one from the <a href="https://alpinegizmo.github.io/flink-docs//apis/streaming/event_timestamp_extractors.html">predefined ones</a>. After doing so,
it can be passed to the consumer in the following way:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="k">new</span> <span class="n">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span>
    <span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">kinesisConsumerConfig</span><span class="o">));</span>
<span class="n">kinesis</span> <span class="o">=</span> <span class="n">kinesis</span><span class="o">.</span><span class="na">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="k">new</span> <span class="nf">CustomTimestampAssigner</span><span class="o">());</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">kinesis</span> <span class="k">=</span> <span class="n">env</span><span class="o">.</span><span class="n">addSource</span><span class="o">(</span><span class="k">new</span> <span class="nc">FlinkKinesisConsumer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span>
    <span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">,</span> <span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">kinesisConsumerConfig</span><span class="o">))</span>
<span class="n">kinesis</span> <span class="k">=</span> <span class="n">kinesis</span><span class="o">.</span><span class="n">assignTimestampsAndWatermarks</span><span class="o">(</span><span class="k">new</span> <span class="nc">CustomTimestampAssigner</span><span class="o">)</span></code></pre></figure>

  </div>
</div>

<h4 id="threading-model">Threading Model</h4>

<p>The Flink Kinesis Consumer uses multiple threads for shard discovery and data consumption.</p>

<p>For shard discovery, each parallel consumer subtask will have a single thread that constantly queries Kinesis for shard
information even if the subtask initially did not have shards to read from when the consumer was started. In other words, if
the consumer is run with a parallelism of 10, there will be a total of 10 threads constantly querying Kinesis regardless
of the total amount of shards in the subscribed streams.</p>

<p>For data consumption, a single thread will be created to consume each discovered shard. Threads will terminate when the
shard it is responsible of consuming is closed as a result of stream resharding. In other words, there will always be
one thread per open shard.</p>

<h4 id="internally-used-kinesis-apis">Internally Used Kinesis APIs</h4>

<p>The Flink Kinesis Consumer uses the <a href="http://aws.amazon.com/sdk-for-java/">AWS Java SDK</a> internally to call Kinesis APIs
for shard discovery and data consumption. Due to Amazon’s <a href="http://docs.aws.amazon.com/streams/latest/dev/service-sizes-and-limits.html">service limits for Kinesis Streams</a>
on the APIs, the consumer will be competing with other non-Flink consuming applications that the user may be running.
Below is a list of APIs called by the consumer with description of how the consumer uses the API, as well as information
on how to deal with any errors or warnings that the Flink Kinesis Consumer may have due to these service limits.</p>

<ul>
  <li>
    <p><em><a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_DescribeStream.html">DescribeStream</a></em>: this is constantly called
by a single thread in each parallel consumer subtask to discover any new shards as a result of stream resharding. By default,
the consumer performs the shard discovery at an interval of 10 seconds, and will retry indefinitely until it gets a result
from Kinesis. If this interferes with other non-Flink consuming applications, users can slow down the consumer of
calling this API by setting a value for <code>ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS</code> in the supplied
configuration properties. This sets the discovery interval to a different value. Note that this setting directly impacts
the maximum delay of discovering a new shard and starting to consume it, as shards will not be discovered during the interval.</p>
  </li>
  <li>
    <p><em><a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html">GetShardIterator</a></em>: this is called
only once when per shard consuming threads are started, and will retry if Kinesis complains that the transaction limit for the
API has exceeded, up to a default of 3 attempts. Note that since the rate limit for this API is per shard (not per stream),
the consumer itself should not exceed the limit. Usually, if this happens, users can either try to slow down any other
non-Flink consuming applications of calling this API, or modify the retry behaviour of this API call in the consumer by
setting keys prefixed by <code>ConsumerConfigConstants.SHARD_GETITERATOR_*</code> in the supplied configuration properties.</p>
  </li>
  <li>
    <p><em><a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetRecords.html">GetRecords</a></em>: this is constantly called
by per shard consuming threads to fetch records from Kinesis. When a shard has multiple concurrent consumers (when there
are any other non-Flink consuming applications running), the per shard rate limit may be exceeded. By default, on each call
of this API, the consumer will retry if Kinesis complains that the data size / transaction limit for the API has exceeded,
up to a default of 3 attempts. Users can either try to slow down other non-Flink consuming applications, or adjust the throughput
of the consumer by setting the <code>ConsumerConfigConstants.SHARD_GETRECORDS_MAX</code> and
<code>ConsumerConfigConstants.SHARD_GETRECORDS_INTERVAL_MILLIS</code> keys in the supplied configuration properties. Setting the former
adjusts the maximum number of records each consuming thread tries to fetch from shards on each call (default is 100), while
the latter modifies the sleep interval between each fetch (there will be no sleep by default). The retry behaviour of the
consumer when calling this API can also be modified by using the other keys prefixed by <code>ConsumerConfigConstants.SHARD_GETRECORDS_*</code>.</p>
  </li>
</ul>

<h3 id="kinesis-producer">Kinesis Producer</h3>

<p>The <code>FlinkKinesisProducer</code> is used for putting data from a Flink stream into a Kinesis stream. Note that the producer is not participating in
Flink’s checkpointing and doesn’t provide exactly-once processing guarantees.
Also, the Kinesis producer does not guarantee that records are written in order to the shards (See <a href="https://github.com/awslabs/amazon-kinesis-producer/issues/23">here</a> and <a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html#API_PutRecord_RequestSyntax">here</a> for more details).</p>

<p>In case of a failure or a resharding, data will be written again to Kinesis, leading to duplicates. This behavior is usually called “at-least-once” semantics.</p>

<p>To put data into a Kinesis stream, make sure the stream is marked as “ACTIVE” in the AWS dashboard.</p>

<p>For the monitoring to work, the user accessing the stream needs access to the Cloud watch service.</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">producerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>

<span class="n">FlinkKinesisProducer</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FlinkKinesisProducer</span><span class="o">&lt;&gt;(</span><span class="k">new</span> <span class="nf">SimpleStringSchema</span><span class="o">(),</span> <span class="n">producerConfig</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setFailOnError</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setDefaultStream</span><span class="o">(</span><span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="na">setDefaultPartition</span><span class="o">(</span><span class="s">&quot;0&quot;</span><span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">simpleStringStream</span> <span class="o">=</span> <span class="o">...;</span>
<span class="n">simpleStringStream</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="n">kinesis</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">producerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>

<span class="k">val</span> <span class="n">kinesis</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FlinkKinesisProducer</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="k">new</span> <span class="nc">SimpleStringSchema</span><span class="o">,</span> <span class="n">producerConfig</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="n">setFailOnError</span><span class="o">(</span><span class="kc">true</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="n">setDefaultStream</span><span class="o">(</span><span class="s">&quot;kinesis_stream_name&quot;</span><span class="o">);</span>
<span class="n">kinesis</span><span class="o">.</span><span class="n">setDefaultPartition</span><span class="o">(</span><span class="s">&quot;0&quot;</span><span class="o">);</span>

<span class="k">val</span> <span class="n">simpleStringStream</span> <span class="k">=</span> <span class="o">...;</span>
<span class="n">simpleStringStream</span><span class="o">.</span><span class="n">addSink</span><span class="o">(</span><span class="n">kinesis</span><span class="o">);</span></code></pre></figure>

  </div>
</div>

<p>The above is a simple example of using the producer. Configuration for the producer with the mandatory configuration values is supplied with a <code>java.util.Properties</code>
instance as described above for the consumer. The example demonstrates producing a single Kinesis stream in the AWS region “us-east-1”.</p>

<p>Instead of a <code>SerializationSchema</code>, it also supports a <code>KinesisSerializationSchema</code>. The <code>KinesisSerializationSchema</code> allows to send the data to multiple streams. This is
done using the <code>KinesisSerializationSchema.getTargetStream(T element)</code> method. Returning <code>null</code> there will instruct the producer to write the element to the default stream.
Otherwise, the returned stream name is used.</p>

<p>Other optional configuration keys for the producer can be found in <code>ProducerConfigConstants</code>.</p>

<h3 id="using-non-aws-kinesis-endpoints-for-testing">Using Non-AWS Kinesis Endpoints for Testing</h3>

<p>It is sometimes desirable to have Flink operate as a consumer or producer against a non-AWS Kinesis endpoint such as
<a href="https://github.com/mhart/kinesalite">Kinesalite</a>; this is especially useful when performing functional testing of a Flink
application. The AWS endpoint that would normally be inferred by the AWS region set in the Flink configuration must be overridden via a configuration property.</p>

<p>To override the AWS endpoint, taking the producer for example, set the <code>ProducerConfigConstants.AWS_ENDPOINT</code> property in the
Flink configuration, in addition to the <code>ProducerConfigConstants.AWS_REGION</code> required by Flink. Although the region is
required, it will not be used to determine the AWS endpoint URL.</p>

<p>The following example shows how one might supply the <code>ProducerConfigConstants.AWS_ENDPOINT</code> configuration property:</p>

<div class="codetabs">
  <div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">Properties</span> <span class="n">producerConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Properties</span><span class="o">();</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">ProducerConfigConstants</span><span class="o">.</span><span class="na">AWS_ENDPOINT</span><span class="o">,</span> <span class="s">&quot;http://localhost:4567&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
  <div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">producerConfig</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Properties</span><span class="o">();</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_REGION</span><span class="o">,</span> <span class="s">&quot;us-east-1&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_ACCESS_KEY_ID</span><span class="o">,</span> <span class="s">&quot;aws_access_key_id&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_SECRET_ACCESS_KEY</span><span class="o">,</span> <span class="s">&quot;aws_secret_access_key&quot;</span><span class="o">);</span>
<span class="n">producerConfig</span><span class="o">.</span><span class="n">put</span><span class="o">(</span><span class="nc">ProducerConfigConstants</span><span class="o">.</span><span class="nc">AWS_ENDPOINT</span><span class="o">,</span> <span class="s">&quot;http://localhost:4567&quot;</span><span class="o">);</span></code></pre></figure>

  </div>
</div>


        </div>
      </div>
    </div><!-- /.container -->

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.1.0/anchor.min.js"></script>
    <script src="https://alpinegizmo.github.io/flink-docs//page/js/flink.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Disqus -->
    
  </body>
</html>
